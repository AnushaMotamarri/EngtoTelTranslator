{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "lines= pd.read_table('uniquew.txt', names=['eng', 'tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2232, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.str.lower()#apply(lambda x: x.lower())\n",
    "lines.tel=lines.tel.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', str(x)))\n",
    "lines.tel=lines.tel.apply(lambda x: re.sub(\"'\", '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.tel=lines.tel.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             definitely\n",
       "1                                             he hung up\n",
       "2                                             i ran home\n",
       "3                                             who are we\n",
       "4                                            are you mad\n",
       "5                                          he touched me\n",
       "6                                          my head hurts\n",
       "7                                         i drank coffee\n",
       "8                                        how tall is she\n",
       "9                                         theyre animals\n",
       "10                                      can you see that\n",
       "11                                      i began to speak\n",
       "12                                      i dislike coffee\n",
       "13                                       im hungry again\n",
       "14                                      i dont accept it\n",
       "15                                      whats in the box\n",
       "16                                     which is your pen\n",
       "17                                    are you feeling ok\n",
       "18                                    help came too late\n",
       "19                                    how are you coming\n",
       "20                                    i do make mistakes\n",
       "21                                     it wasnt my fault\n",
       "22                                     its very valuable\n",
       "23                                     shes not a doctor\n",
       "24                                    we want to hear it\n",
       "25                                    what will you have\n",
       "26                                    where was your son\n",
       "27                                    more coffee please\n",
       "28                                   tom was very scared\n",
       "29                                   what are you saying\n",
       "                             ...                        \n",
       "108                   a cat came out from under the desk\n",
       "109                   how about going out to eat tonight\n",
       "110                   what he says makes no sense at all\n",
       "111                  do you have anything further to say\n",
       "112                   i dont have time to talk right now\n",
       "113                   i dont want to talk to you anymore\n",
       "114                  sitting down all day is bad for you\n",
       "115                  we need to hire people we can trust\n",
       "116                  you can eat lunch here in this room\n",
       "117                  im getting off at the next bus stop\n",
       "118                  its difficult to speak english well\n",
       "119               he is teaching spanish to the children\n",
       "120              he was a great poet as well as a doctor\n",
       "121               i wouldnt go there today if i were you\n",
       "122              she asked me how many languages i spoke\n",
       "123                 when youre a father youll understand\n",
       "124              which color do you prefer blue or green\n",
       "125            do you usually eat breakfast before seven\n",
       "126            it was apparent that there was no way out\n",
       "127           do you know the reason why she is so angry\n",
       "128            i shouldve been able to do that by myself\n",
       "129          are you still afraid something might happen\n",
       "130            its high time you left for school isnt it\n",
       "131          these socks dont stretch when you wash them\n",
       "132          with her heart pounding she opened the door\n",
       "133        can you tell me where the nearest bus stop is\n",
       "134          ive made a mistake though i didnt intend to\n",
       "135       its going to take all afternoon and maybe more\n",
       "136    my father often falls asleep while watching te...\n",
       "137    he has two pencils one is long and the other o...\n",
       "Name: eng, Length: 138, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.tel = lines.tel.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.tel=lines.tel.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.tel=lines.tel.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "lines.tel = lines.tel.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>where did you put my book</td>\n",
       "      <td>START_ నా పుస్తకం ఎక్కడ పెట్టావ్ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>we dont understand french</td>\n",
       "      <td>START_ మాకు ఫ్రెంచి అర్ధం కాదు _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>we havent slept in days</td>\n",
       "      <td>START_ మేము రోజుల తరబడి నిద్రపోలేదు _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>it was apparent that there was no way out</td>\n",
       "      <td>START_ వేరే దారి లేదని స్పష్టంగా తెలుస్తుంది _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>you must stay where you are</td>\n",
       "      <td>START_ నువ్వు ఎక్కడ ఉన్నవో అక్కడే ఉండు _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>i dont trust that guy</td>\n",
       "      <td>START_ నేను వాడిని నమ్మను _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>she scared the cat away</td>\n",
       "      <td>START_ ఆవిడ పిల్లిని భయపెట్టి తరిమేసింది _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>im hungry again</td>\n",
       "      <td>START_ నాకు మళ్ళా ఆకలి వేస్తుంది _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>dont interfere with my work</td>\n",
       "      <td>START_ నా పని లో అడ్డు రాకు _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>the work is almost done</td>\n",
       "      <td>START_ పని దాదాపుగా అయిపోయింది _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           eng  \\\n",
       "68                   where did you put my book   \n",
       "75                   we dont understand french   \n",
       "63                     we havent slept in days   \n",
       "126  it was apparent that there was no way out   \n",
       "80                 you must stay where you are   \n",
       "45                       i dont trust that guy   \n",
       "56                     she scared the cat away   \n",
       "13                             im hungry again   \n",
       "81                 dont interfere with my work   \n",
       "57                     the work is almost done   \n",
       "\n",
       "                                                   tel  \n",
       "68               START_ నా పుస్తకం ఎక్కడ పెట్టావ్ _END  \n",
       "75                 START_ మాకు ఫ్రెంచి అర్ధం కాదు _END  \n",
       "63            START_ మేము రోజుల తరబడి నిద్రపోలేదు _END  \n",
       "126  START_ వేరే దారి లేదని స్పష్టంగా తెలుస్తుంది _END  \n",
       "80         START_ నువ్వు ఎక్కడ ఉన్నవో అక్కడే ఉండు _END  \n",
       "45                      START_ నేను వాడిని నమ్మను _END  \n",
       "56       START_ ఆవిడ పిల్లిని భయపెట్టి తరిమేసింది _END  \n",
       "13               START_ నాకు మళ్ళా ఆకలి వేస్తుంది _END  \n",
       "81                    START_ నా పని లో అడ్డు రాకు _END  \n",
       "57                 START_ పని దాదాపుగా అయిపోయింది _END  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Telugu_words=set()\n",
    "for tel in lines.tel:\n",
    "    for word in tel.split():\n",
    "        if word not in all_Telugu_words:\n",
    "            all_Telugu_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "print(max_length_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.tel:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "\n",
    "print(max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 403\n"
     ]
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_Telugu_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_Telugu_words)\n",
    "print(num_encoder_tokens, num_decoder_tokens)\n",
    "num_decoder_tokens += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         eng  \\\n",
      "112       i dont have time to talk right now   \n",
      "124  which color do you prefer blue or green   \n",
      "93            you may go swimming or fishing   \n",
      "91            we played basketball yesterday   \n",
      "75                 we dont understand french   \n",
      "16                         which is your pen   \n",
      "67                 when did you quit smoking   \n",
      "32                       ill be very careful   \n",
      "81               dont interfere with my work   \n",
      "99           i cant keep you here any longer   \n",
      "\n",
      "                                                   tel  \n",
      "112      START_ నాకు ఇప్పుడు మాట్లాడేంత సమయం లేదు _END  \n",
      "124  START_ నీకు ఏ రంగు అంటే ఇష్టం నీలమా లేక పచ్ఛా ...  \n",
      "93   START_ నువ్వు ఈత కొట్టడానికో లేక చేపలు పట్టడాన...  \n",
      "91          START_ మేము నిన్న బాస్కెట్ బాల్ ఆడాము _END  \n",
      "75                 START_ మాకు ఫ్రెంచి అర్ధం కాదు _END  \n",
      "16                              START_ నీ కలం ఏది _END  \n",
      "67               START_ పొగ తాగడం ఎప్పుడు ఆపేశావ్ _END  \n",
      "32             START_ నేను చాలా జాగ్రత్తగా ఉంటాను _END  \n",
      "81                    START_ నా పని లో అడ్డు రాకు _END  \n",
      "99   START_ నిన్ను ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను ...  \n"
     ]
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "print(lines.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124,) (14,)\n"
     ]
    }
   ],
   "source": [
    "X, y = lines.eng, lines.tel\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('Weights_Tel/X_train.pkl')\n",
    "X_test.to_pickle('Weights_Tel/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 10):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src+1),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar+1),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar+1, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                print( input_text)\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "\n",
    "train_samples,val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 5s 394ms/step - loss: 5.9867 - acc: 0.1727 - val_loss: 5.9441 - val_acc: 0.2083\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 5.6793 - acc: 0.1933 - val_loss: 5.6240 - val_acc: 0.1538\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 5.1944 - acc: 0.1936 - val_loss: 5.3746 - val_acc: 0.2083\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 5.0787 - acc: 0.1959 - val_loss: 5.9172 - val_acc: 0.1538\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 5.0315 - acc: 0.1959 - val_loss: 5.5098 - val_acc: 0.2083\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.0104 - acc: 0.1945 - val_loss: 6.1832 - val_acc: 0.1538\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.9687 - acc: 0.1921 - val_loss: 5.6728 - val_acc: 0.2083\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.9088 - acc: 0.1948 - val_loss: 6.3728 - val_acc: 0.1538\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.8580 - acc: 0.1948 - val_loss: 5.8500 - val_acc: 0.2083\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.8240 - acc: 0.1936 - val_loss: 6.5859 - val_acc: 0.1538\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.7853 - acc: 0.1953 - val_loss: 5.9887 - val_acc: 0.2083\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.7582 - acc: 0.1970 - val_loss: 6.7114 - val_acc: 0.1538\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 4.6838 - acc: 0.2042 - val_loss: 6.1193 - val_acc: 0.2292\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 4.7370 - acc: 0.2044 - val_loss: 6.9121 - val_acc: 0.1538\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 4.6458 - acc: 0.2026 - val_loss: 6.2868 - val_acc: 0.2292\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 4.5996 - acc: 0.2067 - val_loss: 7.1408 - val_acc: 0.1538\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 4.5448 - acc: 0.2140 - val_loss: 6.3469 - val_acc: 0.2292\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.5053 - acc: 0.2151 - val_loss: 6.8562 - val_acc: 0.1538\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 4.4956 - acc: 0.2134 - val_loss: 6.3092 - val_acc: 0.2292\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 4.4738 - acc: 0.2092 - val_loss: 6.8028 - val_acc: 0.1538\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.4294 - acc: 0.2124 - val_loss: 6.5102 - val_acc: 0.2292\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 4.3791 - acc: 0.2155 - val_loss: 7.1230 - val_acc: 0.1538\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 4.3519 - acc: 0.2143 - val_loss: 6.6629 - val_acc: 0.2500\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 4.3314 - acc: 0.2146 - val_loss: 7.3762 - val_acc: 0.1923\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 4.3105 - acc: 0.2143 - val_loss: 6.7642 - val_acc: 0.2500\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 4.2450 - acc: 0.2129 - val_loss: 7.3745 - val_acc: 0.1923\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.3233 - acc: 0.2124 - val_loss: 6.8608 - val_acc: 0.2500\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 4.2212 - acc: 0.2183 - val_loss: 7.4452 - val_acc: 0.1923\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 4.1678 - acc: 0.2173 - val_loss: 7.0367 - val_acc: 0.2500\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 4.1160 - acc: 0.2219 - val_loss: 7.6049 - val_acc: 0.1538\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.0820 - acc: 0.2274 - val_loss: 6.7568 - val_acc: 0.2292\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 4.0686 - acc: 0.2249 - val_loss: 7.2509 - val_acc: 0.1923\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 4.0470 - acc: 0.2268 - val_loss: 6.8561 - val_acc: 0.2292\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 3.9965 - acc: 0.2234 - val_loss: 7.6270 - val_acc: 0.1538\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 3.9469 - acc: 0.2329 - val_loss: 7.1923 - val_acc: 0.2292\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 3.9085 - acc: 0.2269 - val_loss: 7.5477 - val_acc: 0.1923\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 3.8926 - acc: 0.2305 - val_loss: 7.1409 - val_acc: 0.2083\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 3.8604 - acc: 0.2272 - val_loss: 7.6520 - val_acc: 0.1923\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 3.7816 - acc: 0.2367 - val_loss: 7.3554 - val_acc: 0.2083\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 3.8733 - acc: 0.2301 - val_loss: 7.6874 - val_acc: 0.1923\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 3.7514 - acc: 0.2391 - val_loss: 7.0474 - val_acc: 0.2083\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 3.6952 - acc: 0.2471 - val_loss: 7.9372 - val_acc: 0.1923\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 3.6535 - acc: 0.2428 - val_loss: 7.0031 - val_acc: 0.2083\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 3.6167 - acc: 0.2549 - val_loss: 7.6667 - val_acc: 0.1538\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 3.6029 - acc: 0.2520 - val_loss: 7.2064 - val_acc: 0.2083\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 3.5746 - acc: 0.2540 - val_loss: 7.7066 - val_acc: 0.1538\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 3.5247 - acc: 0.2537 - val_loss: 7.3678 - val_acc: 0.2083\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 3.4824 - acc: 0.2601 - val_loss: 7.6793 - val_acc: 0.1923\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 3.4644 - acc: 0.2579 - val_loss: 7.3320 - val_acc: 0.2083\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 3.4308 - acc: 0.2653 - val_loss: 7.8316 - val_acc: 0.1538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efba0227cc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = int(train_samples/batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = int(val_samples/batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: i began to speak\n",
      "Actual Tel Translation:  నేను మాట్లాడటం మొదలుపెట్టాను \n",
      "Predicted Tel Translation:  ఆమె నిన్న లో \n",
      "Input English sentence: help came too late\n",
      "Actual Tel Translation:  సహాయం చాలా ఆలస్యముగా వచ్చింది \n",
      "Predicted Tel Translation:  నీ \n",
      "Input English sentence: he made her a bookshelf\n",
      "Actual Tel Translation:  అతను ఆమెకి పుస్తకాల అర తయారు చేసాడు \n",
      "Predicted Tel Translation:  నాకు నాకు కావాలని కాదు \n",
      "Input English sentence: he touched me\n",
      "Actual Tel Translation:  అతను నన్ను తాకాడు \n",
      "Predicted Tel Translation:  నాకు \n",
      "Input English sentence: are you mad\n",
      "Actual Tel Translation:  కోపమొచ్చిందా \n",
      "Predicted Tel Translation:  నువ్వు చాలా లేదు \n",
      "Input English sentence: when youre a father youll understand\n",
      "Actual Tel Translation:  నువ్వు నాన్న అయినప్పుడు నీకు అర్ధం అవుతుంది \n",
      "Predicted Tel Translation:  ఆమె నిన్న లో \n",
      "Input English sentence: it actually isnt that simple\n",
      "Actual Tel Translation:  అది అంత సులభం ఏం కాదు \n",
      "Predicted Tel Translation:  నువ్వు చాలా కాదు \n",
      "Input English sentence: when did you quit smoking\n",
      "Actual Tel Translation:  పొగ తాగడం ఎప్పుడు ఆపేశావ్ \n",
      "Predicted Tel Translation:  నాకు కాఫీ \n",
      "Input English sentence: what will you have\n",
      "Actual Tel Translation:  నువ్వు ఏమి తీసుకుంటావ్ \n",
      "Predicted Tel Translation:  నాకు నాకు \n",
      "Input English sentence: are you feeling ok\n",
      "Actual Tel Translation:  వొంట్లో ఎలా వుంది \n",
      "Predicted Tel Translation:  నువ్వు చాలా కాదు \n",
      "Input English sentence: do you usually eat breakfast before seven\n",
      "Actual Tel Translation:  నువ్వు మాములుగా ఏడు కు ముందే టిఫిన చెస్తావా \n",
      "Predicted Tel Translation:  నాకు నాకు ఇంకా సమయం కాదు \n",
      "Input English sentence: im not allowed to do that here\n",
      "Actual Tel Translation:  అది ఇక్కడ చెయ్యడానికి నాకు అనుమతి లేదు \n",
      "Predicted Tel Translation:  నువ్వు ఒక అంత సమయం కాదు \n",
      "Input English sentence: he washed the blood off his hands\n",
      "Actual Tel Translation:  అతడు తన చేతులకి అంటిన రక్తాన్ని కడిగేసాడు \n",
      "Predicted Tel Translation:  నాకు నాకు ఇంకా కాదు \n",
      "Input English sentence: shes not a doctor\n",
      "Actual Tel Translation:  ఆమె వైద్యురాలు కాదు \n",
      "Predicted Tel Translation:  నేను చాలా కాదు \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-eeb59c484852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "while(k<182):\n",
    "    k+=1\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    inp=X_test[k:k+1].values[0]\n",
    "    act=y_test[k:k+1].values[0][6:-4]\n",
    "    pred=decoded_sentence[:-4]\n",
    "    print('Input English sentence:', inp)\n",
    "    print('Actual Tel Translation:',act )\n",
    "    print('Predicted Tel Translation:', pred)\n",
    "    \n",
    "    if(act==pred):\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
